{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlQ--Xoco-FA"
   },
   "source": [
    "# Tutorial 8 - Recommender Systems Part II  \n",
    "\n",
    "Last week, we looked at loading and exploring datasets with users' feedback and played with a range of recommendation techniques, such as non-personalized approaches and traditional collaborative filtering approaches. We also introduced simple evaluation settings for rating prediction tasks on top of the Surprise package. This tutorial explores an alternative technique for collaborative filtering using latent factor models, on both rating prediction and ranking prediction tasks, with simple TensorFlow recipes. Furthermore, this tutorial covers a range of train-test splits, the creation of recommended lists, and the computation of decision-support and rank-aware top-k metrics that are fundamental for the evaluation of recommender systems.   \n",
    "\n",
    "**Expected Tasks**\n",
    "\n",
    "- Follow the latent factor models showcase in TensorFlow.\n",
    "- Solve a range of exercises throughout the notebook. \n",
    "\n",
    "**Learning Objectives**\n",
    "\n",
    "- Load and explore dataset with users' feedback. \n",
    "- Implement a train-test split technique. \n",
    "- Create and train a latent factor model.\n",
    "- Compute the recommended list of a given user. \n",
    "- Evaluate a recommender systems, using different metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0NAa-SicMd7B"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy.sparse as sp\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "import time \n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\mirko\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (4.50.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 21.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7hbi1zgo7XR"
   },
   "source": [
    "## Step #1: Load the Movielens 1M data set\n",
    "---\n",
    "\n",
    "**Reference**: Harper, F. M., & Konstan, J. A. (2015). The Movielens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TIIS), 5(4), 1-19. [https://dl.acm.org/doi/10.1145/2827872](https://dl.acm.org/doi/10.1145/2827872). \n",
    "\n",
    "The MovieLens datasets, first released in 1998, describe people’s expressed preferences for movies. These preferences take the form of <user, item, rating, timestamp> tuples, each the result of a person expressing a preference (a 0–5 star rating) for a movie at a particular time. These preferences were entered by way of the MovieLens website, a recommender system that asks its users to give movie ratings in order to receive personalized movie recommendations. \n",
    "\n",
    "The MovieLens datasets are heavily downloaded and referenced in the research literature. This popularity is, to a certain degree, a reflection of the incredible rate of growth of personalization and recommendation research, in which datasets such as these have substantial value in exploring and validating ideas. The popularity might also be attributed to the flexibility of ratings data. Also, because movie preferences are highly subject to personal tastes, the movie domain is well suited to testing personalization technology. Finally, the popularity may reflect the perceived accessibility of movies as a content domain: movies are a common interest, making algorithmic output easy to discuss. \n",
    "\n",
    "In this tutorial, we will play with a small version of a dataset collected from the Movielens platform. Specifically, we will use the MovieLens 1M movie ratings dataset ([https://grouplens.org/datasets/movielens/1m/](https://grouplens.org/datasets/movielens/1m/)), with 1 million ratings from 6000 users on 4000 movies. The dataset includes information about **ratings**, **movies**, **users**. \n",
    "\n",
    "All **ratings** are contained in the file \"ratings.dat\" and are in the following format: user_id::item_id::rating::timestamp. \n",
    "- User IDs range between 1 and 6040. \n",
    "- Item IDs range between 1 and 3952.\n",
    "- Ratings are made on a 5-star scale (whole-star ratings only). \n",
    "- Timestamp is represented in seconds since the epoch as returned by time. \n",
    "- Each user has at least 20 ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4onM3ObBla4m"
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', names=['user_id', 'item_id', 'rating', 'timestamp'],engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "z7N5crOymEcU",
    "outputId": "b57c584a-e693-436b-b382-236ccbe17b9f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5744</th>\n",
       "      <td>42</td>\n",
       "      <td>2140</td>\n",
       "      <td>3</td>\n",
       "      <td>978040305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65638</th>\n",
       "      <td>438</td>\n",
       "      <td>1219</td>\n",
       "      <td>4</td>\n",
       "      <td>981602428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43588</th>\n",
       "      <td>300</td>\n",
       "      <td>3082</td>\n",
       "      <td>2</td>\n",
       "      <td>976507505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114562</th>\n",
       "      <td>744</td>\n",
       "      <td>2762</td>\n",
       "      <td>4</td>\n",
       "      <td>975472452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526501</th>\n",
       "      <td>3257</td>\n",
       "      <td>2918</td>\n",
       "      <td>5</td>\n",
       "      <td>968276069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946810</th>\n",
       "      <td>5717</td>\n",
       "      <td>1029</td>\n",
       "      <td>4</td>\n",
       "      <td>958744684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159102</th>\n",
       "      <td>1017</td>\n",
       "      <td>2420</td>\n",
       "      <td>4</td>\n",
       "      <td>975011604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45481</th>\n",
       "      <td>307</td>\n",
       "      <td>1256</td>\n",
       "      <td>5</td>\n",
       "      <td>976485814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504113</th>\n",
       "      <td>3099</td>\n",
       "      <td>3257</td>\n",
       "      <td>4</td>\n",
       "      <td>969593848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805749</th>\n",
       "      <td>4823</td>\n",
       "      <td>1902</td>\n",
       "      <td>2</td>\n",
       "      <td>1000086880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  rating   timestamp\n",
       "5744         42     2140       3   978040305\n",
       "65638       438     1219       4   981602428\n",
       "43588       300     3082       2   976507505\n",
       "114562      744     2762       4   975472452\n",
       "526501     3257     2918       5   968276069\n",
       "946810     5717     1029       4   958744684\n",
       "159102     1017     2420       4   975011604\n",
       "45481       307     1256       5   976485814\n",
       "504113     3099     3257       4   969593848\n",
       "805749     4823     1902       2  1000086880"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yEIdZKJOmGmD",
    "outputId": "62766cf9-2d66-4086-9ca6-ccb526c0646f"
   },
   "outputs": [],
   "source": [
    "no_users, no_items, no_ratings = len(ratings.user_id.unique()), len(ratings.item_id.unique()), len(ratings.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706, 1000209)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_users, no_items, no_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we load the movies. All movies information is in the file \"movies.dat\" and is in the following format: item_id::title::genres. \n",
    "\n",
    "- Titles are identical to titles provided by the IMDB (including year of release). \n",
    "- Genres are pipe-separated and are selected from the following genres (Action, Adventure, Animation, Children's, Comedy, Crime, Documentary, Drama, Fantasy, Film-Noir, Horror, Musical, Mystery, Romance, Sci-Fi, Thriller, War, Wester). \n",
    "- Some MovieIDs do not correspond to a movie due to accidental duplicate entries and/or test entries. \n",
    "- Movies are mostly entered by hand, so errors and inconsistencies may exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('ml-1m/movies.dat', sep='::', names=['item_id', 'title', 'genres'], engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                               title                        genres\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIvKhIjksFZR"
   },
   "source": [
    "For convenience, we re-scale the user ids from $0$ to $|\\text{no_users}-1|$ and the item ids from $0$ to $|\\text{no_items}-1|$. This pre-processing step will allow us to use the id as an index in the latent factors matrices of users and items. For convenience, we also keep two columns with the original user ids and item ids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ejwUFstRsINf"
   },
   "outputs": [],
   "source": [
    "ratings['original_user_id'] = ratings['user_id']\n",
    "ratings['original_item_id'] = ratings['item_id']\n",
    "ratings['user_id'] = ratings['user_id'].astype('category').cat.codes\n",
    "ratings['item_id'] = ratings['item_id'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 6039, 0, 3705)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(ratings['user_id']), max(ratings['user_id']), min(ratings['item_id']), max(ratings['item_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO5eP_o1pEqn"
   },
   "source": [
    "## Step #2: Define the evaluation method\n",
    "---\n",
    "\n",
    "Before delving into latent factor models, as we have seen in the lectures, we need to decide the **evaluation method** to apply in our analysis. The evaluation method in use depends on the data and the context. For instance, in some cases, you may opt for a **train-test split** (split data into a train and a test set). In other cases, a **cross-validation** might be more appropriate (split data into folds, hold out each in turn for testing). Once you decide the overall evaluation method, you need to define **how the data will be split** in train-test or across folds. Very common solutions require to sample a percentage of ratings to be included in the test set or to sample a fixed percentage or number (same for all) of ratings for each user in the test set. Another strategy is based on sampling a percentage of users (first-level) whose ratings are included in the training set and, for the users in the test set, applying another splitting strategies (second-level). Furthermore, such a split may be done randomly or by considering the timestamps of when user-item interactions were performed. \n",
    "\n",
    "### Exercise #1 \n",
    "\n",
    "In the following cell, we ask you to split the interactions in <code>ratings</code> in two disjoint dataframes <code>train_ratings</code> and <code>test ratings</code>, according to a train-test split strategy that takes the 20% most recent ratings for each user in the test set, while the rest of the ratings are added to the training set. During or after the tutorial, in the following cell, you could also implement other strategies among the ones listed above and inspect how the performance varies according to the splitting strategy; you just need to re-run the other cells then.   \n",
    "\n",
    "Note that <code>train_ratings</code> and <code>test ratings</code> should have the same four columns of the original dataframe <code>ratings</code>. The train and test dataframes just differ in terms of rows (i.e., interactions).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "g65rlT51mN0L"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [00:04<00:00, 1454.05it/s]\n"
     ]
    }
   ],
   "source": [
    "### EXERCISE CELL ###\n",
    "perc_test_ratings = 0.2\n",
    "\n",
    "train_samples, test_samples = [], []\n",
    "\n",
    "for user_id, user_ratings in tqdm(ratings.groupby(['user_id'])):\n",
    "    sorted_user_ratings = user_ratings.sort_values('timestamp')\n",
    "    no_test_ratings = int(len(sorted_user_ratings.index) * perc_test_ratings)\n",
    "    train_samples.append(sorted_user_ratings.head(len(sorted_user_ratings.index) - no_test_ratings))\n",
    "    test_samples.append(sorted_user_ratings.tail(no_test_ratings))\n",
    "    \n",
    "train_ratings = pd.concat(train_samples)\n",
    "test_ratings = pd.concat(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wre9zSDmdUT",
    "outputId": "f7cebb03-cbcc-44e2-eff6-3104247e694e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(802553, 6040, 3666)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ratings.index), len(train_ratings['user_id'].unique()), len(train_ratings['item_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTvMDqxemqKp",
    "outputId": "fb18958d-efae-4cc5-843d-fa7feed2f244"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197656, 6040, 3532)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ratings.index), len(test_ratings['user_id'].unique()), len(test_ratings['item_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What pros and cons does this evaluation method (i.e., train-test split) have?\n",
    "- Is the selected splitting strategy a good simulation of a real-world situation? If not, why?\n",
    "- Do you have any argument on why the number of items is different between the training and test sets? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0XwyW27qB4y"
   },
   "source": [
    "## Step #3: Define the latent factor model\n",
    "---\n",
    "\n",
    "In the previous tutorial, we showed recommendation models aimed at factorizing a rating matrix based on dimensionality reduction techniques, such as Singular Value Decomposition (SVD). However, the rating matrix is only partially observed and it is really large. Methods like SVD are not defined for partially observed matrices, and they are not often practical for large matrices with thousands or millions of users and items. Latent factor models have been introduced to solve the matrix factorization problem approximately using (stochastic) gradient descent. Specifically, the general equation can be expressed as:\n",
    "\n",
    "$R = Q P^T$\n",
    "\n",
    "where: \n",
    "- $R$ is a rating matrix with $m$ items and $n$ users\n",
    "- $Q$ is an item latent factor matrix of size ($m, f$), with $f$ being the number of item factors.  \n",
    "- $P$ is an user latent factor matrix of size ($f, n$), with $f$ being the number of user factors. \n",
    "\n",
    "To create and train a latent factor model, we will use short recipes in TensorFlow. For those who are not familiar with this package, you may find useful to go over this [TensorFlow tutorial for beginners](https://www.tensorflow.org/tutorials/quickstart/beginner). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the number of factors we will use for item and user latent vectors. For a first trial, we will initialize it to 10, but you will be asked to inspect the impact of the number of factors on the performance later in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "P5OK5xB6m2UM"
   },
   "outputs": [],
   "source": [
    "no_factors = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow latent factor models\n",
    "\n",
    "The traditional definition of latent factor models is based on a shallow learning methodology. Basically, we create and initialize two matrices: a <code>user_matrix</code> and an <code>item_matrix</code>. Then, given a pair of <code>user_id</code> and <code>item_id</code>, we select the latent factors associated to that user and item from the two matrices, obtaining <code>user_vector</code> and <code>item_vector</code>. Finally, we compute the dot product between the vectors, namely the predicted rating (the ourpur of our model).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "UUASKPU0m5B0"
   },
   "outputs": [],
   "source": [
    "def create_shallow_model(no_factors, no_users, no_items):\n",
    "    # User branch\n",
    "    user_id = tf.keras.layers.Input(shape=[1], name='user_id')\n",
    "    user_matrix = tf.keras.layers.Embedding(no_users+1, no_factors, name='user_matrix')(user_id)\n",
    "    user_vector = tf.keras.layers.Flatten(name='user_vector')(user_matrix)\n",
    "    # Item branch\n",
    "    item_id = tf.keras.layers.Input(shape=[1], name='item_id')\n",
    "    item_matrix = tf.keras.layers.Embedding(no_items+1, no_factors, name='item_matrix')(item_id)\n",
    "    item_vector = tf.keras.layers.Flatten(name='item_vector')(item_matrix)\n",
    "    # Dot product \n",
    "    vectors_product = tf.keras.layers.dot([user_vector, item_vector], axes=1, normalize=False)\n",
    "    # Model definition\n",
    "    model = tf.keras.models.Model(inputs=[user_id, item_id], outputs=[vectors_product], name='shallow_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_shallow_model(no_factors, no_users, no_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visually show our shallow latent factor model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "Vgp1GwLRm62m",
    "outputId": "6f338ad6-91b8-466f-8167-6f577cacc59b"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"274pt\" viewBox=\"0.00 0.00 638.00 304.00\" width=\"576pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(0.9 0.9) rotate(0) translate(4 300)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-300 634,-300 634,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 1880992771544 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>1880992771544</title>\n",
       "<polygon fill=\"none\" points=\"23,-249.5 23,-295.5 283,-295.5 283,-249.5 23,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-268.8\">user_id: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"148,-249.5 148,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"148,-272.5 204,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"204,-249.5 204,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243.5\" y=\"-280.3\">[(None, 1)]</text>\n",
       "<polyline fill=\"none\" points=\"204,-272.5 283,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243.5\" y=\"-257.3\">[(None, 1)]</text>\n",
       "</g>\n",
       "<!-- 1881055567376 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>1881055567376</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 306,-212.5 306,-166.5 0,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"76\" y=\"-185.8\">user_matrix: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"152,-166.5 152,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"152,-189.5 208,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"208,-166.5 208,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-197.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"208,-189.5 306,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-174.3\">(None, 1, 100)</text>\n",
       "</g>\n",
       "<!-- 1880992771544&#45;&gt;1881055567376 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>1880992771544-&gt;1881055567376</title>\n",
       "<path d=\"M153,-249.37C153,-241.15 153,-231.66 153,-222.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.5,-222.61 153,-212.61 149.5,-222.61 156.5,-222.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1879076618928 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>1879076618928</title>\n",
       "<polygon fill=\"none\" points=\"347,-249.5 347,-295.5 607,-295.5 607,-249.5 347,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"409.5\" y=\"-268.8\">item_id: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"472,-249.5 472,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"500\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"472,-272.5 528,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"500\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"528,-249.5 528,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"567.5\" y=\"-280.3\">[(None, 1)]</text>\n",
       "<polyline fill=\"none\" points=\"528,-272.5 607,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"567.5\" y=\"-257.3\">[(None, 1)]</text>\n",
       "</g>\n",
       "<!-- 1879076621952 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>1879076621952</title>\n",
       "<polygon fill=\"none\" points=\"324,-166.5 324,-212.5 630,-212.5 630,-166.5 324,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"400\" y=\"-185.8\">item_matrix: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"476,-166.5 476,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"504\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"476,-189.5 532,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"504\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"532,-166.5 532,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"581\" y=\"-197.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"532,-189.5 630,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"581\" y=\"-174.3\">(None, 1, 100)</text>\n",
       "</g>\n",
       "<!-- 1879076618928&#45;&gt;1879076621952 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>1879076618928-&gt;1879076621952</title>\n",
       "<path d=\"M477,-249.37C477,-241.15 477,-231.66 477,-222.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"480.5,-222.61 477,-212.61 473.5,-222.61 480.5,-222.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1881055573608 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>1881055573608</title>\n",
       "<polygon fill=\"none\" points=\"24.5,-83.5 24.5,-129.5 305.5,-129.5 305.5,-83.5 24.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"88\" y=\"-102.8\">user_vector: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"151.5,-83.5 151.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"179.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"151.5,-106.5 207.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"179.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"207.5,-83.5 207.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256.5\" y=\"-114.3\">(None, 1, 100)</text>\n",
       "<polyline fill=\"none\" points=\"207.5,-106.5 305.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256.5\" y=\"-91.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 1881055567376&#45;&gt;1881055573608 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>1881055567376-&gt;1881055573608</title>\n",
       "<path d=\"M156.28,-166.37C157.5,-158.15 158.9,-148.66 160.23,-139.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.72,-140.01 161.72,-129.61 156.8,-138.99 163.72,-140.01\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1879164393960 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>1879164393960</title>\n",
       "<polygon fill=\"none\" points=\"329.5,-83.5 329.5,-129.5 610.5,-129.5 610.5,-83.5 329.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"393\" y=\"-102.8\">item_vector: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"456.5,-83.5 456.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"484.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"456.5,-106.5 512.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"484.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"512.5,-83.5 512.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"561.5\" y=\"-114.3\">(None, 1, 100)</text>\n",
       "<polyline fill=\"none\" points=\"512.5,-106.5 610.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"561.5\" y=\"-91.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 1879076621952&#45;&gt;1879164393960 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>1879076621952-&gt;1879164393960</title>\n",
       "<path d=\"M475.09,-166.37C474.38,-158.15 473.56,-148.66 472.78,-139.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"476.26,-139.27 471.91,-129.61 469.28,-139.87 476.26,-139.27\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1880992768632 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>1880992768632</title>\n",
       "<polygon fill=\"none\" points=\"171,-0.5 171,-46.5 457,-46.5 457,-0.5 171,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.5\" y=\"-19.8\">dot: Dot</text>\n",
       "<polyline fill=\"none\" points=\"234,-0.5 234,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"234,-23.5 290,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"290,-0.5 290,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373.5\" y=\"-31.3\">[(None, 100), (None, 100)]</text>\n",
       "<polyline fill=\"none\" points=\"290,-23.5 457,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373.5\" y=\"-8.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 1881055573608&#45;&gt;1880992768632 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>1881055573608-&gt;1880992768632</title>\n",
       "<path d=\"M205.71,-83.37C223.86,-73.5 245.41,-61.79 264.48,-51.42\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"266.22,-54.46 273.33,-46.61 262.88,-48.31 266.22,-54.46\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1879164393960&#45;&gt;1880992768632 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>1879164393960-&gt;1880992768632</title>\n",
       "<path d=\"M427.37,-83.37C408.28,-73.46 385.61,-61.68 365.57,-51.28\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"367.06,-48.11 356.58,-46.61 363.84,-54.32 367.06,-48.11\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True, show_layer_names=True, rankdir='HB', dpi=65).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the model.summary() to print a range of model characteristics, such as the number of trainable parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zw9cGYtIm9p2",
    "outputId": "ab0d0f9c-3708-4984-edfb-2ccf26994b28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"shallow_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_matrix (Embedding)         (None, 1, 100)       604100      user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_matrix (Embedding)         (None, 1, 100)       370700      item_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_vector (Flatten)           (None, 100)          0           user_matrix[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "item_vector (Flatten)           (None, 100)          0           item_matrix[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1)            0           user_vector[0][0]                \n",
      "                                                                 item_vector[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 974,800\n",
      "Trainable params: 974,800\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can you describe how the input data is transformed to the final output? \n",
    "- Why do the item_matrix and user_matrix layers return a vector of size (1, 10) each? \n",
    "- Why does the user_matrix layer have 604100 parameters? \n",
    "- Why does the item_matrix layer have 370700 parameters? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep latent factor models (gift provided in this tutorial)\n",
    "\n",
    "In both the lecture and in the first part of this tutorial, we have seen that the rating is predicted by multiplying the two latent vectors. However, recent advances in the field have shown that it is possible to predict the rating by combining the two latent factors (e.g., with a concatenation) and making transformations to the combined vector in cascade with fully-connected layers (deep neural networks). In what follows, we can see an example of how a deep latent factor model can be defined. Please, pay attention to the concatenation and how the cascade of fully-connected layers is defined.\n",
    "\n",
    "Those who are interested in going into the details of this type of approaches may start by reading a milestone paper iin the field:\n",
    "\n",
    "- He, X., Liao, L., Zhang, H., Nie, L., Hu, X., & Chua, T. S. (2017). Neural Collaborative Filtering. In: WWW 2017 (pp. 173-182)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deep_model(no_factors, no_users, no_items):\n",
    "    # User branch\n",
    "    user_id = tf.keras.layers.Input(shape=[1], name='user_id')\n",
    "    user_matrix = tf.keras.layers.Embedding(no_users+1, no_factors, name='user_matrix')(user_id)\n",
    "    user_vector = tf.keras.layers.Flatten(name='user_vector')(user_matrix)\n",
    "    # Item branch\n",
    "    item_id = tf.keras.layers.Input(shape=[1], name='item_id')\n",
    "    item_matrix = tf.keras.layers.Embedding(no_items+1, no_factors, name='item_matrix')(item_id)\n",
    "    item_vector = tf.keras.layers.Flatten(name='item_vector')(item_matrix)\n",
    "    # Concantenation\n",
    "    vectors_concat = tf.keras.layers.Concatenate()([user_vector, item_vector])\n",
    "    vectors_concat_dropout = tf.keras.layers.Dropout(0.2)(vectors_concat)\n",
    "    # Backbone \n",
    "    dense_1 = tf.keras.layers.Dense(16,name='fc3')(vectors_concat_dropout)\n",
    "    dropout_1 = tf.keras.layers.Dropout(0.2,name='d3')(dense_1)\n",
    "    dense_2 = tf.keras.layers.Dense(8,name='fc4', activation='relu')(dropout_1)\n",
    "    dense_2_output = tf.keras.layers.Dense(1, activation='relu', name='activation')(dense_2)\n",
    "    # Model definition\n",
    "    model = tf.keras.models.Model(inputs=[user_id, item_id], outputs=[dense_2_output], name='deep_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_deep_model(no_factors, no_users, no_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"649pt\" viewBox=\"0.00 0.00 638.00 719.00\" width=\"576pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(0.9 0.9) rotate(0) translate(4 715)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-715 634,-715 634,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 1879263107056 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>1879263107056</title>\n",
       "<polygon fill=\"none\" points=\"23,-664.5 23,-710.5 283,-710.5 283,-664.5 23,-664.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-683.8\">user_id: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"148,-664.5 148,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"148,-687.5 204,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"204,-664.5 204,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243.5\" y=\"-695.3\">[(None, 1)]</text>\n",
       "<polyline fill=\"none\" points=\"204,-687.5 283,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243.5\" y=\"-672.3\">[(None, 1)]</text>\n",
       "</g>\n",
       "<!-- 1879128529944 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>1879128529944</title>\n",
       "<polygon fill=\"none\" points=\"0,-581.5 0,-627.5 306,-627.5 306,-581.5 0,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"76\" y=\"-600.8\">user_matrix: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"152,-581.5 152,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"152,-604.5 208,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"208,-581.5 208,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-612.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"208,-604.5 306,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-589.3\">(None, 1, 100)</text>\n",
       "</g>\n",
       "<!-- 1879263107056&#45;&gt;1879128529944 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>1879263107056-&gt;1879128529944</title>\n",
       "<path d=\"M153,-664.37C153,-656.15 153,-646.66 153,-637.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156.5,-637.61 153,-627.61 149.5,-637.61 156.5,-637.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1879128508680 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>1879128508680</title>\n",
       "<polygon fill=\"none\" points=\"347,-664.5 347,-710.5 607,-710.5 607,-664.5 347,-664.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"409.5\" y=\"-683.8\">item_id: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"472,-664.5 472,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"500\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"472,-687.5 528,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"500\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"528,-664.5 528,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"567.5\" y=\"-695.3\">[(None, 1)]</text>\n",
       "<polyline fill=\"none\" points=\"528,-687.5 607,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"567.5\" y=\"-672.3\">[(None, 1)]</text>\n",
       "</g>\n",
       "<!-- 1879076618480 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>1879076618480</title>\n",
       "<polygon fill=\"none\" points=\"324,-581.5 324,-627.5 630,-627.5 630,-581.5 324,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"400\" y=\"-600.8\">item_matrix: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"476,-581.5 476,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"504\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"476,-604.5 532,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"504\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"532,-581.5 532,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"581\" y=\"-612.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"532,-604.5 630,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"581\" y=\"-589.3\">(None, 1, 100)</text>\n",
       "</g>\n",
       "<!-- 1879128508680&#45;&gt;1879076618480 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>1879128508680-&gt;1879076618480</title>\n",
       "<path d=\"M477,-664.37C477,-656.15 477,-646.66 477,-637.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"480.5,-637.61 477,-627.61 473.5,-637.61 480.5,-637.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1879076618592 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>1879076618592</title>\n",
       "<polygon fill=\"none\" points=\"24.5,-498.5 24.5,-544.5 305.5,-544.5 305.5,-498.5 24.5,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"88\" y=\"-517.8\">user_vector: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"151.5,-498.5 151.5,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"179.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"151.5,-521.5 207.5,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"179.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"207.5,-498.5 207.5,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256.5\" y=\"-529.3\">(None, 1, 100)</text>\n",
       "<polyline fill=\"none\" points=\"207.5,-521.5 305.5,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256.5\" y=\"-506.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 1879128529944&#45;&gt;1879076618592 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>1879128529944-&gt;1879076618592</title>\n",
       "<path d=\"M156.28,-581.37C157.5,-573.15 158.9,-563.66 160.23,-554.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.72,-555.01 161.72,-544.61 156.8,-553.99 163.72,-555.01\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1879128482984 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>1879128482984</title>\n",
       "<polygon fill=\"none\" points=\"329.5,-498.5 329.5,-544.5 610.5,-544.5 610.5,-498.5 329.5,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"393\" y=\"-517.8\">item_vector: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"456.5,-498.5 456.5,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"484.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"456.5,-521.5 512.5,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"484.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"512.5,-498.5 512.5,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"561.5\" y=\"-529.3\">(None, 1, 100)</text>\n",
       "<polyline fill=\"none\" points=\"512.5,-521.5 610.5,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"561.5\" y=\"-506.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 1879076618480&#45;&gt;1879128482984 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>1879076618480-&gt;1879128482984</title>\n",
       "<path d=\"M475.09,-581.37C474.38,-573.15 473.56,-563.66 472.78,-554.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"476.26,-554.27 471.91,-544.61 469.28,-554.87 476.26,-554.27\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1879128506720 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>1879128506720</title>\n",
       "<polygon fill=\"none\" points=\"123.5,-415.5 123.5,-461.5 504.5,-461.5 504.5,-415.5 123.5,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.5\" y=\"-434.8\">concatenate: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"281.5,-415.5 281.5,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"309.5\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"281.5,-438.5 337.5,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"309.5\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"337.5,-415.5 337.5,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-446.3\">[(None, 100), (None, 100)]</text>\n",
       "<polyline fill=\"none\" points=\"337.5,-438.5 504.5,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-423.3\">(None, 200)</text>\n",
       "</g>\n",
       "<!-- 1879076618592&#45;&gt;1879128506720 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>1879076618592-&gt;1879128506720</title>\n",
       "<path d=\"M205.71,-498.37C223.86,-488.5 245.41,-476.79 264.48,-466.42\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"266.22,-469.46 273.33,-461.61 262.88,-463.31 266.22,-469.46\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1879128482984&#45;&gt;1879128506720 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>1879128482984-&gt;1879128506720</title>\n",
       "<path d=\"M427.37,-498.37C408.28,-488.46 385.61,-476.68 365.57,-466.28\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"367.06,-463.11 356.58,-461.61 363.84,-469.32 367.06,-463.11\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1879051484352 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>1879051484352</title>\n",
       "<polygon fill=\"none\" points=\"186.5,-332.5 186.5,-378.5 441.5,-378.5 441.5,-332.5 186.5,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.5\" y=\"-351.8\">dropout: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"302.5,-332.5 302.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"330.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"302.5,-355.5 358.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"330.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"358.5,-332.5 358.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"400\" y=\"-363.3\">(None, 200)</text>\n",
       "<polyline fill=\"none\" points=\"358.5,-355.5 441.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"400\" y=\"-340.3\">(None, 200)</text>\n",
       "</g>\n",
       "<!-- 1879128506720&#45;&gt;1879051484352 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>1879128506720-&gt;1879051484352</title>\n",
       "<path d=\"M314,-415.37C314,-407.15 314,-397.66 314,-388.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"317.5,-388.61 314,-378.61 310.5,-388.61 317.5,-388.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1879126787240 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>1879126787240</title>\n",
       "<polygon fill=\"none\" points=\"206.5,-249.5 206.5,-295.5 421.5,-295.5 421.5,-249.5 206.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.5\" y=\"-268.8\">fc3: Dense</text>\n",
       "<polyline fill=\"none\" points=\"282.5,-249.5 282.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"282.5,-272.5 338.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"338.5,-249.5 338.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"380\" y=\"-280.3\">(None, 200)</text>\n",
       "<polyline fill=\"none\" points=\"338.5,-272.5 421.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"380\" y=\"-257.3\">(None, 16)</text>\n",
       "</g>\n",
       "<!-- 1879051484352&#45;&gt;1879126787240 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>1879051484352-&gt;1879126787240</title>\n",
       "<path d=\"M314,-332.37C314,-324.15 314,-314.66 314,-305.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"317.5,-305.61 314,-295.61 310.5,-305.61 317.5,-305.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1879128565576 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>1879128565576</title>\n",
       "<polygon fill=\"none\" points=\"205,-166.5 205,-212.5 423,-212.5 423,-166.5 205,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247.5\" y=\"-185.8\">d3: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"290,-166.5 290,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"318\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"290,-189.5 346,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"318\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"346,-166.5 346,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"384.5\" y=\"-197.3\">(None, 16)</text>\n",
       "<polyline fill=\"none\" points=\"346,-189.5 423,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"384.5\" y=\"-174.3\">(None, 16)</text>\n",
       "</g>\n",
       "<!-- 1879126787240&#45;&gt;1879128565576 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>1879126787240-&gt;1879128565576</title>\n",
       "<path d=\"M314,-249.37C314,-241.15 314,-231.66 314,-222.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"317.5,-222.61 314,-212.61 310.5,-222.61 317.5,-222.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1879126903776 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>1879126903776</title>\n",
       "<polygon fill=\"none\" points=\"209.5,-83.5 209.5,-129.5 418.5,-129.5 418.5,-83.5 209.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247.5\" y=\"-102.8\">fc4: Dense</text>\n",
       "<polyline fill=\"none\" points=\"285.5,-83.5 285.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"285.5,-106.5 341.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"341.5,-83.5 341.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"380\" y=\"-114.3\">(None, 16)</text>\n",
       "<polyline fill=\"none\" points=\"341.5,-106.5 418.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"380\" y=\"-91.3\">(None, 8)</text>\n",
       "</g>\n",
       "<!-- 1879128565576&#45;&gt;1879126903776 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>1879128565576-&gt;1879126903776</title>\n",
       "<path d=\"M314,-166.37C314,-158.15 314,-148.66 314,-139.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"317.5,-139.61 314,-129.61 310.5,-139.61 317.5,-139.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1879126904504 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>1879126904504</title>\n",
       "<polygon fill=\"none\" points=\"195.5,-0.5 195.5,-46.5 432.5,-46.5 432.5,-0.5 195.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"251\" y=\"-19.8\">activation: Dense</text>\n",
       "<polyline fill=\"none\" points=\"306.5,-0.5 306.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"334.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"306.5,-23.5 362.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"334.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"362.5,-0.5 362.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.5\" y=\"-31.3\">(None, 8)</text>\n",
       "<polyline fill=\"none\" points=\"362.5,-23.5 432.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.5\" y=\"-8.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 1879126903776&#45;&gt;1879126904504 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>1879126903776-&gt;1879126904504</title>\n",
       "<path d=\"M314,-83.37C314,-75.15 314,-65.66 314,-56.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"317.5,-56.61 314,-46.61 310.5,-56.61 317.5,-56.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True, show_layer_names=True, rankdir='HB', dpi=65).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By printing the summary, you can get an idea of the number of parameters to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deep_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_matrix (Embedding)         (None, 1, 100)       604100      user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_matrix (Embedding)         (None, 1, 100)       370700      item_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_vector (Flatten)           (None, 100)          0           user_matrix[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "item_vector (Flatten)           (None, 100)          0           item_matrix[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 200)          0           user_vector[0][0]                \n",
      "                                                                 item_vector[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 200)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fc3 (Dense)                     (None, 16)           3216        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "d3 (Dropout)                    (None, 16)           0           fc3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc4 (Dense)                     (None, 8)            136         d3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "activation (Dense)              (None, 1)            9           fc4[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 978,161\n",
      "Trainable params: 978,161\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To what extent a deep latent factor model is powerful for this data and context?\n",
    "- How can we decide on the number and size of the fully-connected layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #4: Optimize the latent factor model\n",
    "---\n",
    "\n",
    "Once we define the architecture of our latent factor model, we can move on the optimization phase. In this part, we will focus on the shallow latent factor model, but you can easily inspect how the same analysis works for deep latent factor models later in the tutorial or after the tutorial. To start optimizing, we need to define the input data (pairs of user ids and item ids in the training set) and the ourput data (the ground-truth ratings). We initialize the model by capitalizing on the creation function defined previously. Then, we need to tell to the model how it will be optimized. This is done by the compile method. In this case, we adopt mean squared error, leaving experiments with other loss functions as a future work. Finally, we invoke the train method of the model, by passing the train data and labels, the number of epoches (number of times each training sample is seen by the model), and the size of the batches used during optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "igO48-rWm-8E",
    "outputId": "5d7af225-08b6-4e7c-ff20-ec3af7a24b4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "392/392 [==============================] - 6s 12ms/step - loss: 13.5527\n",
      "Epoch 2/10\n",
      "392/392 [==============================] - 6s 15ms/step - loss: 2.4448\n",
      "Epoch 3/10\n",
      "392/392 [==============================] - 5s 13ms/step - loss: 1.0335\n",
      "Epoch 4/10\n",
      "392/392 [==============================] - 5s 13ms/step - loss: 0.8840\n",
      "Epoch 5/10\n",
      "392/392 [==============================] - 5s 13ms/step - loss: 0.8447\n",
      "Epoch 6/10\n",
      "392/392 [==============================] - 5s 12ms/step - loss: 0.8271: 0s - lo\n",
      "Epoch 7/10\n",
      "392/392 [==============================] - 5s 12ms/step - loss: 0.8081: 0s \n",
      "Epoch 8/10\n",
      "392/392 [==============================] - 5s 12ms/step - loss: 0.7903: 2s - \n",
      "Epoch 9/10\n",
      "392/392 [==============================] - 5s 12ms/step - loss: 0.7739\n",
      "Epoch 10/10\n",
      "392/392 [==============================] - 5s 13ms/step - loss: 0.7578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b584aaad30>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input-output data definition\n",
    "X_train = [train_ratings.user_id, train_ratings.item_id]\n",
    "y_train = train_ratings.rating\n",
    "\n",
    "# Model creation\n",
    "model = create_shallow_model(no_factors, no_users, no_items)\n",
    "\n",
    "# Model compiling \n",
    "model.compile(loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "# Model training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=2048, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you reach this point, the latent factors are optimized, and you are ready to move to the next step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #5: Predict the user-item ratings\n",
    "---\n",
    "\n",
    "The next step requires to make predictions on the user-item ratings. Specifically, we are interested in comparing the performance of the model in the training and test set, to assess the extent to which the model performance can generalize on unseen data. To make predictions, we can use the <code>predict</code> method of the model. This method takes pairs of user ids and item ids (similarly to the <code>fit</code> method) and returns the corresponding predicted ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions in the training set\n",
    "X_train = [train_ratings.user_id, train_ratings.item_id]\n",
    "y_train = train_ratings.rating\n",
    "y_train_pred = model.predict(X_train, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions in the test set\n",
    "X_test = [test_ratings.user_id, test_ratings.item_id]\n",
    "y_test = test_ratings.rating\n",
    "y_test_pred = model.predict(X_test, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3.7901554],\n",
       "        [3.8163054],\n",
       "        [4.151822 ],\n",
       "        ...,\n",
       "        [4.127607 ],\n",
       "        [3.9790115],\n",
       "        [3.7053754]], dtype=float32),\n",
       " array([[4.085388 ],\n",
       "        [3.986267 ],\n",
       "        [4.7016344],\n",
       "        ...,\n",
       "        [3.6738548],\n",
       "        [2.933577 ],\n",
       "        [4.390311 ]], dtype=float32))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred, y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #6: Evaluate a latent factor model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction accuracy metrics\n",
    "\n",
    "As seen in the last lecture, prediction accuracy metrics monitor the error rate in rating prediction. To this end, we need datasets with items rated by users (as ml-1m) and the historical user ratings constitute ground truth. The traditional prediction accuracy metrics are MAE Mean Absolute Error, MSE Mean Squared Error, RMSE Root Mean Squared Error (the most-widely used). In this tutorial, we show you how to compure the RMSE for the training and the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.85574374836874\n",
      "Test RMSE: 0.9084470639988373\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print('Train RMSE:', mean_squared_error(y_train.values, y_train_pred, squared=False))\n",
    "print('Test RMSE:', mean_squared_error(y_test.values, y_test_pred, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision-support metrics\n",
    "\n",
    "Decision-support metrics measure how well a recommender helps users make good decisions. Good decisions are about choosing “relevant” items and avoiding “irrelevant” ones. The main decision-support metrics are P Precision and R Recall.\n",
    "\n",
    "- Precision is a measure of exactness and determines the fraction of relevant items retrieved out of all items retrieved, e.g., the proportion of recommended items actually relevant. Specifically, precision is about returning mostly relevant/useful items, to not waste user time. The assumption is that there is more relevant items than you want. \n",
    "\n",
    "- Recall is a measure of completeness and determines the fraction of relevant items retrieved out of all relevant items, e.g., the proportion of all relevant items recommended. Specifically, recall is about not missing relevant items,  i.e., not making a bad oversight. The assumption is that you have time to filter through results to find the items you need. \n",
    "\n",
    "Given that this definition covers the entire data set and does not target top-recommended items, it has been introduced the notion of cutoff k: the size of the recommended list. Specifically, Precision@k is the percentage of the top-k items that are “relevant”, and Recall@k is the percentage of the “relevant” items recommended in the top-k items. \n",
    "\n",
    "Please, refer to [Lecture 8 slides](https://moodle.epfl.ch/pluginfile.php/2903092/mod_resource/content/10/mlbeh_8_recsys_part2.pdf) for the formulas and the examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differently from prediction accuracy metrics, decision-support metrics require to compute the list recommended to the user. To this end, for each user, we identify the items already seen in the training phase and those who put apart for the test set. Then, we make the rating predictions for all items for that user, and we force a very low rating for items already seen in the training set (in such a way that they cannot be recommended anymore, the user might not want to get recommended a movie he or she has already seen). Finally, we sort the items based on decreasing predicted rating, and we take the top-k items. Based on this items, we are able to compute the main decision-support metrics, such as precision and recall.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "3o4cjO6vn4Op"
   },
   "outputs": [],
   "source": [
    "def predict_from_latent(model, uid, pids, train_ratings=None):\n",
    "    user_vector = model.get_layer('user_matrix').get_weights()[0][uid]\n",
    "    item_vectors = model.get_layer('item_matrix').get_weights()[0][pids]\n",
    "    scores = (np.dot(user_vector, item_vectors.T))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "tk6vN2Z4n6z_"
   },
   "outputs": [],
   "source": [
    "def precision_at_k(model, pred_func, train_ratings, test_ratings, no_users, no_items, k=10):\n",
    "    pid_array = np.arange(no_items, dtype=np.int32)\n",
    "    precisions = []\n",
    "    # For each user\n",
    "    for user_id, user_test_rating in tqdm(test_ratings.groupby('user_id')):\n",
    "        # Retrieve already-seen items\n",
    "        train_pids = train_ratings[train_ratings['user_id'] == user_id]['item_id'].values\n",
    "        # Retrieve the unseen items\n",
    "        test_pids = set(user_test_rating['item_id'].values)\n",
    "        # Make rating predictions for all items for that user\n",
    "        predictions = pred_func(model, user_id, pid_array, train_ratings)\n",
    "        # Force a low rating to already-seen items\n",
    "        predictions[train_pids] = - math.inf\n",
    "        # Sort the items and het the top k\n",
    "        top_k = set(np.argsort(-predictions)[:k])\n",
    "        # Compute precision as per definition\n",
    "        precisions.append(len(top_k & test_pids) / float(k))\n",
    "    return precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fS4k_SP8oCYJ",
    "outputId": "5f220fe4-6911-41d4-abcc-ae9827c6326a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [01:11<00:00, 84.38it/s] \n"
     ]
    }
   ],
   "source": [
    "precisions = precision_at_k(model, predict_from_latent, train_ratings, test_ratings, no_users, no_items, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.02076158940397351, 0.07177560771163459)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(precisions), np.std(precisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise #2.1\n",
    "\n",
    "In the following cell, we ask you to define a function that returns a list with the recalls for all users, individually. Specifically, the signature of the required function should be as follows: \n",
    "<code>recall_at_k(model, pred_func, train_ratings, test_ratings, no_users, no_items, k=10)</code>\n",
    "\n",
    "The returned value is a list of recalls, one per user, as similarly done for precision computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXERCISE CELL ###\n",
    "def recall_at_k(model, pred_func, train_ratings, test_ratings, no_users, no_items, k=10):\n",
    "    pid_array = np.arange(no_items, dtype=np.int32)\n",
    "    recalls = []\n",
    "    for user_id, user_test_rating in tqdm(test_ratings.groupby('user_id')):\n",
    "        train_pids = train_ratings[train_ratings['user_id'] == user_id]['item_id'].values\n",
    "        test_pids = set(user_test_rating['item_id'].values)\n",
    "        predictions = pred_func(model, user_id, pid_array, train_ratings)\n",
    "        predictions[train_pids] = - math.inf\n",
    "        top_k = set(np.argsort(-predictions)[:k])\n",
    "        recalls.append(len(top_k & test_pids) / len(test_pids))\n",
    "    return recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [01:05<00:00, 92.04it/s] \n"
     ]
    }
   ],
   "source": [
    "recalls = recall_at_k(model, predict_from_latent, train_ratings, test_ratings, no_users, no_items, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0048361920053578075, 0.019185999298448674)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(recalls), np.std(recalls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank-aware top-k metrics\n",
    "\n",
    "What we have seen so far (prediction accuracy and decision-support metrics) monitors how accurate the predictions are and how good a recommender system is at finding items. Now, when the recommender list the items, we are interested more in where are the relevant items are placed, and how good the recommender is at predicting relative preference between items. Rank-aware top-k metrics depend on the notion of relevance and take into account the position an item has been recommended. \n",
    "\n",
    "### Exercise #2.2\n",
    "In the following cell, we ask you to define a function that returns a list with the Mean Average Precisions (MAPs) for all users, individually. Specifically, the signature of the required function should be as follows: <code>map_at_k(model, pred_func, train_ratings, test_ratings, no_users, no_items, k=10)</code>. \n",
    "\n",
    "The returned value is a list of MAPs, one per user, as similarly done for precision and recall computation.\n",
    "\n",
    "Please, refer to [Lecture 8 slides](https://moodle.epfl.ch/pluginfile.php/2903092/mod_resource/content/10/mlbeh_8_recsys_part2.pdf) for the formulas and the examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXERCISE CELL ###\n",
    "def map_at_k(model, pred_func, train_ratings, test_ratings, no_users, no_items, k=10):\n",
    "    pid_array = np.arange(no_items, dtype=np.int32)\n",
    "    maps = []\n",
    "    for user_id, user_test_rating in tqdm(test_ratings.groupby('user_id')):\n",
    "        train_pids = train_ratings[train_ratings['user_id'] == user_id]['item_id'].values\n",
    "        test_pids = set(user_test_rating['item_id'].values)\n",
    "        predictions = pred_func(model, user_id, pid_array, train_ratings)\n",
    "        predictions[train_pids] = - math.inf\n",
    "        partial_maps = []\n",
    "        top_k = list(np.argsort(-predictions)[:k])\n",
    "        for rank, item_id in enumerate(top_k):\n",
    "            if item_id in test_pids:\n",
    "                partial_maps.append(len(set(top_k[:rank+1]) & test_pids) / float(rank+1))\n",
    "        maps.append(.0 if len(partial_maps) == 0 else np.sum(partial_maps) / float(k))\n",
    "    return maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [01:13<00:00, 82.35it/s]\n"
     ]
    }
   ],
   "source": [
    "maps = map_at_k(model, predict_from_latent, train_ratings, test_ratings, no_users, no_items, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.009218727005150846, 0.048460988543363635)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(maps), np.std(maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise #3\n",
    "\n",
    "1. Train four shallow latent factor models on train_ratings, with 5, 25, 50, and 100 factors, respectively. Other parameters stay as per the previous examples. \n",
    "2. Compute the precisions for all users achieved by the four models in test_ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing with number of factors 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [00:29<00:00, 204.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing with number of factors 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [00:26<00:00, 225.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing with number of factors 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [00:40<00:00, 147.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing with number of factors 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [01:13<00:00, 82.29it/s]\n"
     ]
    }
   ],
   "source": [
    "### EXERCISE CELL ###\n",
    "X_train = [train_ratings.user_id, train_ratings.item_id]\n",
    "y_train = train_ratings.rating\n",
    "\n",
    "metrics = {}\n",
    "for no_factors in [5, 25, 50, 100]:\n",
    "    print('Playing with number of factors', no_factors)\n",
    "    # Create and fit the model\n",
    "    model = create_shallow_model(no_factors, no_users, no_items)\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError())\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=2048, shuffle=True, verbose=0)\n",
    "    # Compute precision scores\n",
    "    precisions = precision_at_k(model, predict_from_latent, train_ratings, test_ratings, no_users, no_items, k=10)\n",
    "    metrics[no_factors] = precisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Visually report the precisions by means of error bars. \n",
    "\n",
    "\n",
    "- What is the impact of the number of factors on the performance?\n",
    "- Do you have any argument on why these patterns arise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### EXERCISE CELL ###\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Compute means, standard deviations, and labels\n",
    "means, yerrs, labels = [], [], []\n",
    "for no_factors, model_scores in metrics.items():\n",
    "    means.append(np.mean(model_scores))\n",
    "    yerrs.append(np.std(model_scores))\n",
    "    labels.append(no_factors)\n",
    "\n",
    "# Plot values\n",
    "x_pos = np.arange(len(labels))\n",
    "plt.bar(x_pos, means, yerr=yerrs, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "\n",
    "# Make decorations\n",
    "plt.xticks(x_pos, labels)\n",
    "plt.ylabel('Precision@10')\n",
    "plt.xlabel('Number of factors')\n",
    "plt.ylim(.0, .2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise #4\n",
    "\n",
    "In the following cell, we ask you to define a <code>predict_from_pop</code> that returns a numpy array of popularity scores, one per item (i.e., how many ratings that item has received in the data set). Specifically, we ask you to adhere to the following function signature: \n",
    "\n",
    "<code>predict_from_pop(model, uid, pids, train_ratings)</code>\n",
    "\n",
    "This function should return a list of size $|\\text{no_items}|$, where the cell at position $i$ represents the popularity of the item $i$ in the training data set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXERCISE CELL ###\n",
    "def predict_from_pop(model, uid, pids, train_ratings):\n",
    "    num_ratings = train_ratings.groupby('item_id')['rating'].count()\n",
    "    num_ratings.name = 'num_ratings'\n",
    "    scores = pd.DataFrame(index=pids).merge(num_ratings, left_index=True, right_index=True, how='left').fillna(0)\n",
    "    return scores['num_ratings'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a quick example of usage to see whether the function works properly. First, we compute the scores for a certain user, e.g., user 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3706"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = predict_from_pop(model, [1], np.arange(no_items), train_ratings)\n",
    "\n",
    "len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sort the popularity scores in decreasing order to retrieve the scaled item ids of the most popular items. For each of them, we print the rank and the original item id (not the scaled one).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0 2858\n",
      "# 1 1196\n",
      "# 2 260\n",
      "# 3 1210\n",
      "# 4 2028\n",
      "# 5 480\n",
      "# 6 589\n",
      "# 7 2571\n",
      "# 8 1270\n",
      "# 9 1198\n"
     ]
    }
   ],
   "source": [
    "for rank, item_id in enumerate(np.argsort(-scores)[:10]):\n",
    "    original_item_id = train_ratings[train_ratings['item_id'] == item_id]['original_item_id'].values[0]\n",
    "    print('#', rank, original_item_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a double check, let's retrieve the top-10 most popular items directly as done in the previous tutorial. Please, remember that the items dataframe uses the original item ids and not the scaled ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>num_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2789</th>\n",
       "      <td>2858</td>\n",
       "      <td>American Beauty (1999)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>3167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>1196</td>\n",
       "      <td>Star Wars: Episode V - The Empire Strikes Back...</td>\n",
       "      <td>Action|Adventure|Drama|Sci-Fi|War</td>\n",
       "      <td>2742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>260</td>\n",
       "      <td>Star Wars: Episode IV - A New Hope (1977)</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>2709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>1210</td>\n",
       "      <td>Star Wars: Episode VI - Return of the Jedi (1983)</td>\n",
       "      <td>Action|Adventure|Romance|Sci-Fi|War</td>\n",
       "      <td>2663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>2028</td>\n",
       "      <td>Saving Private Ryan (1998)</td>\n",
       "      <td>Action|Drama|War</td>\n",
       "      <td>2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>480</td>\n",
       "      <td>Jurassic Park (1993)</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>2409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>589</td>\n",
       "      <td>Terminator 2: Judgment Day (1991)</td>\n",
       "      <td>Action|Sci-Fi|Thriller</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>2571</td>\n",
       "      <td>Matrix, The (1999)</td>\n",
       "      <td>Action|Sci-Fi|Thriller</td>\n",
       "      <td>2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>1270</td>\n",
       "      <td>Back to the Future (1985)</td>\n",
       "      <td>Comedy|Sci-Fi</td>\n",
       "      <td>2315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>1198</td>\n",
       "      <td>Raiders of the Lost Ark (1981)</td>\n",
       "      <td>Action|Adventure</td>\n",
       "      <td>2301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id                                              title  \\\n",
       "2789     2858                             American Beauty (1999)   \n",
       "1178     1196  Star Wars: Episode V - The Empire Strikes Back...   \n",
       "257       260          Star Wars: Episode IV - A New Hope (1977)   \n",
       "1192     1210  Star Wars: Episode VI - Return of the Jedi (1983)   \n",
       "1959     2028                         Saving Private Ryan (1998)   \n",
       "476       480                               Jurassic Park (1993)   \n",
       "585       589                  Terminator 2: Judgment Day (1991)   \n",
       "2502     2571                                 Matrix, The (1999)   \n",
       "1250     1270                          Back to the Future (1985)   \n",
       "1180     1198                     Raiders of the Lost Ark (1981)   \n",
       "\n",
       "                                   genres  num_ratings  \n",
       "2789                         Comedy|Drama         3167  \n",
       "1178    Action|Adventure|Drama|Sci-Fi|War         2742  \n",
       "257       Action|Adventure|Fantasy|Sci-Fi         2709  \n",
       "1192  Action|Adventure|Romance|Sci-Fi|War         2663  \n",
       "1959                     Action|Drama|War         2440  \n",
       "476               Action|Adventure|Sci-Fi         2409  \n",
       "585                Action|Sci-Fi|Thriller         2389  \n",
       "2502               Action|Sci-Fi|Thriller         2336  \n",
       "1250                        Comedy|Sci-Fi         2315  \n",
       "1180                     Action|Adventure         2301  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe with information about the number of received ratings per item\n",
    "num_ratings = train_ratings.groupby('original_item_id')['rating'].count()\n",
    "num_ratings.name = 'num_ratings'\n",
    "num_ratings.head() \n",
    "\n",
    "tmp_items = items.copy()\n",
    "tmp_items = tmp_items.merge(num_ratings, left_on='item_id', right_index=True)\n",
    "\n",
    "tmp_items.sort_values('num_ratings', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rankings coincide, so the function works as expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise #5\n",
    "\n",
    "- Train a shallow latent factor model on train_ratings, in the same way seen in the cells above.  \n",
    "- Create a grid with two plots, one for precision and one for recall. Each plot should include two error bars: the first one showing the scores achieved by the latent factor model and the second one showing the scores achieved by a recommender that suggests the same most popular items to all users (please use the predict_from_pop function appropriately). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b58ef1ac88>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### EXERCISE CELL ###\n",
    "X_train = [train_ratings.user_id, train_ratings.item_id]\n",
    "y_train = train_ratings.rating\n",
    "\n",
    "model = create_shallow_model(100, no_users, no_items)\n",
    "model.compile(loss=tf.keras.losses.MeanSquaredError())\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=2048, shuffle=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [00:57<00:00, 105.53it/s]\n",
      "100%|██████████| 6040/6040 [05:32<00:00, 18.17it/s]\n",
      "100%|██████████| 6040/6040 [01:01<00:00, 97.65it/s] \n",
      "100%|██████████| 6040/6040 [05:32<00:00, 18.18it/s]\n"
     ]
    }
   ],
   "source": [
    "### EXERCISE CELL ###\n",
    "metrics = {}\n",
    "for metr_func, metr_label in zip([precision_at_k, recall_at_k], ['Precision@10', 'Recall@10']):\n",
    "    metrics[metr_label] = {}\n",
    "    for pred_func, pred_label in zip([predict_from_latent, predict_from_pop], ['LFM', 'MostPop']):\n",
    "        metric_scores = metr_func(model, pred_func, train_ratings, test_ratings, no_users, no_items, k=10)\n",
    "        metrics[metr_label][pred_label] = metric_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAFgCAYAAABNIolGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgJklEQVR4nO3de5RlZ1kn4N9rR65yCRhnxgQhSGLEEUGbIINgRAJBlHhBCcisyDBmVLJ0YLwERSiC44CgzDiiJkocRMcA3mg1iBEI4iXQHYmBRANNROgsZ9mQEESSQCfv/FG79VB2p6uSOjlf1Xmetc6qvb/97XPeWr2q17t+59t7V3cHAAAAYGSfs+gCAAAAAI5EgAEAAAAMT4ABAAAADE+AAQAAAAxPgAEAAAAMT4ABAAAADG+uAUZVnVZVV1fV3qo65xDHv6eq3ltVl1fVn1bVQ2eOvWA67+qqetI86wQAtga9BQAsr+ru+bxx1Y4k709yapJ9SXYneUZ3XzUz597d/Ylp+6lJvq+7T5uajd9IcnKSL0zyx0lO7O5b5lIsADA8vQUALLd5rsA4Ocne7r6muz+d5MIkp89OONhgTO6Z5GCacnqSC7v75u7+2yR7p/cDAJaX3gIAlthRc3zvY5N8ZGZ/X5JHrZ1UVc9N8vwkd0ny+JlzL11z7rGHOPesJGclyT3vec+vOumkkzalcABg/S677LKPdvcxd8JH6S0AYAkcrreYZ4CxLt396iSvrqpnJnlhkjM3cO75Sc5Pkp07d/aePXvmUyQAcFhV9XeLrmGW3gIAtrbD9RbzvITk2iQPmNk/bho7nAuTfPPtPBcA2P70FgCwxOYZYOxOckJVHV9Vd0lyRpJdsxOq6oSZ3ack+cC0vSvJGVV116o6PskJSd49x1oBgPHpLQBgic3tEpLuPlBVZyd5S5IdSS7o7iur6twke7p7V5Kzq+oJST6T5PpMSzyneW9IclWSA0me6y7hALDc9BYAsNzm9hjVO5vrVAFgMarqsu7eueg6NpveAgAW43C9xTwvIQEAAADYFAIMAAAAYHgCDAAAAGB4AgwAAABgeAIMAAAAYHgCDAAAAGB4AgwAAABgeAIMAAAAYHgCDAAAAGB4AgwAAABgeAIMAAAAYHgCDAAAAGB4AgwAAABgeAIMAAAAYHgCDAAAAGB4AgwAAABgeAIMAAAAYHgCDAAAAGB4AgwAAABgeAIMAAAAYHgCDAAAAGB4AgwAAABgeAIMAAAAYHgCDAAAAGB4AgwAAABgeAIMAAAAYHgCDAAAAGB4AgwAAABgeAIMAAAAYHgCDAAAAGB4AgwAAABgeAIMAAAAYHgCDAAAAGB4AgwAAABgeAIMAAAAYHgCDAAAAGB4AgwAAABgeAIMAAAAYHgCDAAAAGB4AgwAAABgeAIMAO6QlZWVVNWmvVZWVhb9KwEAMKCjFl0AAFvbysrKEUOHU045JUlyySWXzL0eAAC2JyswAAAAgOEJMAAAAIDhzTXAqKrTqurqqtpbVecc4vjzq+qqqrqiqt5aVQ+cOXZLVV0+vXbNs04AYHz6CgBYbnO7B0ZV7Ujy6iSnJtmXZHdV7eruq2amvSfJzu7+VFV9b5KfSvL06diN3f3wedUHAGwd+goAYJ4rME5Osre7r+nuTye5MMnpsxO6++3d/alp99Ikx82xHgBg69JXAMCSm2eAcWySj8zs75vGDuc5Sd48s3+3qtpTVZdW1Tcf6oSqOmuas2f//v13uGAAYFhz7ysSvQUAjGyIx6hW1bOS7EzytTPDD+zua6vqwUneVlXv7e4Pzp7X3ecnOT9Jdu7c2XdawQDAsG5vX5HoLQBgZPNcgXFtkgfM7B83jX2WqnpCkh9L8tTuvvngeHdfO/28JsklSR4xx1oBgLHpKwBgyc0zwNid5ISqOr6q7pLkjCSfddfvqnpEkvOy2mT8w8z40VV112n785M8JsnsTboAgOWirwCAJTe3S0i6+0BVnZ3kLUl2JLmgu6+sqnOT7OnuXUlekeTzkryxqpLkw9391CRfmuS8qro1qyHLy9bcZRwAWCL6CgBgrvfA6O6Lkly0ZuxFM9tPOMx5f57ky+dZGwCwtegrAGC5zfMSEgAAAIBNIcAAAAAAhifAAAAAAIYnwAAAAACGJ8AAAAAAhifAAAAAAIYnwAAAAACGJ8AAAAAAhifAAAAAAIYnwAAAAACGJ8AAAAAAhifAAAAAAIYnwAAAAACGJ8AAAAAAhifAAAAAAIYnwAAAAACGJ8AAAAAAhifAAAAAAIYnwAAAAACGJ8AAAAAAhifAAAAAAIYnwAAAAACGJ8AAAAAAhifAAAAAAIYnwAAAAACGJ8AAAAAAhifAAAAAAIYnwAAAAACGJ8AAAAAAhifAAAAAAIYnwAAAAACGJ8AAAAAAhifAAAAAAIYnwAAAAACGJ8AAAAAAhifAAAAAAIYnwAAAAACGJ8AAAAAAhifAAAAAAIYnwAAAAACGJ8AAAAAAhifAAAAAAIYnwAAAAACGJ8AAAAAAhjfXAKOqTquqq6tqb1Wdc4jjz6+qq6rqiqp6a1U9cObYmVX1gel15jzrBAC2Br0FACyvuQUYVbUjyauTPDnJQ5M8o6oeumbae5Ls7O6HJfnNJD81nXu/JC9O8qgkJyd5cVUdPa9aAYDx6S0AYLnNcwXGyUn2dvc13f3pJBcmOX12Qne/vbs/Ne1emuS4aftJSS7u7uu6+/okFyc5bY61AgDj01sAwBKbZ4BxbJKPzOzvm8YO5zlJ3ryRc6vqrKraU1V79u/ffwfLBQAGp7cAgCU2xE08q+pZSXYmecVGzuvu87t7Z3fvPOaYY+ZTHACw5egtAGD7mWeAcW2SB8zsHzeNfZaqekKSH0vy1O6+eSPnAgBLRW8BAEtsngHG7iQnVNXxVXWXJGck2TU7oaoekeS8rDYY/zBz6C1JnlhVR0832HriNAYALC+9BQAssaPm9cbdfaCqzs5qc7AjyQXdfWVVnZtkT3fvyuqyzs9L8saqSpIPd/dTu/u6qnppVhuVJDm3u6+bV60AwPj0FgCw3OYWYCRJd1+U5KI1Yy+a2X7CbZx7QZIL5lcdALDV6C0AYHkNcRNPAAAAgNsiwAAAAACGJ8AAAAAAhifAAAAAAIYnwAAAAACGJ8AAAAAAhifAAAAAAIYnwAAAAACGJ8AAAAAAhifAAAAAAIYnwAAAAACGJ8AAAAAAhifAAAAAAIYnwAAAAACGJ8AAAAAAhifAAAAAAIYnwAAAAACGd9R6JlXVk5J8c5Jjp6Frk7ypu/9wTnUBAAAA/LMjBhhV9T+TnJjkV5Psm4aPS/L9VfXk7v6B+ZUHAAAAsL4VGN/Q3SeuHayq1yd5fxIBBgAAADBX67kHxk1V9chDjD8yyU2bXA8AAADAv7KeFRjfleQXqupe+ZdLSB6Q5IbpGAAAAMBcHTHA6O6/TPKoqvq3mbmJZ3f/v7lWBgAAADBZ11NIkmQKLD4rtKiqk7r7bza9KgAAAIAZ6w4wDuOPknzRZhQCACyHqjoqyXOSfEuSL5yGr03ypiSv6e7PLKo2AGBc63mM6s8e7lCS+25qNQDAMnhdko8nWclnP6L9zCS/luTpC6kKABjaelZgPDvJf0ty8yGOPWNzywEAlsBXHeIR7fuSXFpV719EQQDA+NYTYOxO8r7u/vO1B6pqZdMrAgC2u+uq6tuT/FZ335okVfU5Sb49yfULrQwAGNZ6AoynJbnpUAe6+/jNLQcAWAJnJHl5kp+vqoOBxX2TvH06BgDwr6znMarX3RmFAADLobs/lOk+F1V1/2nsY4usCQAY37qeQlJVn5vkB5I8+eBQkncmeWl3H5hTbQDANrc2uKiqU7v74kXVAwCM63OONKGq7pbkzUk+luSJ3f313f34JB9M8qKq+vJpDgDAHfWaRRcAAIxpPSswfjjJ67v7V6rql6vqwdN4TT/fneTbsvooNACA21RVuw53KMn978xaAICtYz0BxlOSPGbavi7JH2R1RcZpSR6d5A+zGl6sbH55AMA29Ngkz0ryyTXjleTkO78cAGArWE+AcfeZ+1w8vrt/OEmq6k1JXtjdP1JVO+ZWIQCw3Vya5FPd/Y61B6rq6gXUAwBsAesJMK6qqpO7+91J3lRVb0xycZInJPm9qvqSJB+aY40AwDbS3U++jWOPuzNrAQC2jvUEGC9L8r+r6ond/dKqeliSk5L8RJIPJPn9JC+YY40AwDY2PUr1+u6+ddG1AADjOuJTSLr78iSvSPInVfWcJLckuSLJVya5JMl50+oMAIB1qaqjq+rnquodSV6d5M1VdUFV3XPRtQEAY1rPCox0966pwfiOJN87Db8vyZO7+7p5FQcAbD9Vdd8kFyX50e4+e2b865K8rKrekORKPQYAMGtdAUaSdPcNSX5pjrUAAMvhx5O8srvfXlWvS/LVST6a5POTvDerTyN5YZLnL65EAGA0R7yE5KCqekxVXVxV76+qaw6+5lkcALAtPa67f2vavjnJM7r70UmenuRjSf40ydctqjgAYEzrXoGR5DVJnpfksqzeBwMA4Pa4W1VVd3dW76n1V9P4+5J8ZXffWlWLqw4AGNJGAowbuvvNc6sEAFgW707y9Un+OMnPJ/mjqvqLJI9Ocl5VPTLJlQusDwAY0EYCjLdX1SuS/HZWl3smSbr7Lze9KgBgO/vvSd5QVU/p7l+uqt9N8uAkP5PVy1t3JTlzgfUBAANa9z0wkjwqyc4kP5nkp6fXK2/rhKo6raqurqq9VXXOIY4/rqr+sqoOVNXT1hy7paoun167NlAnADCw7r4myXOT7Kqql2a1x7hfkrOT/H6SH+ruq9eep68AgOW2kaeQbOhmWlW1I6vPdT81yb4ku6tqV3dfNTPtw0m+K8kPHuItbuzuh2/kMwGAraG731VVj87qpSRfMQ1fmuQnuvvA2vn6CgBg3QFGVd0nyYuTPG4aekeSc6fHqx7KyUn2Tt+ypKouTHJ6kn9uNLr7Q9OxWzdcOQCwpXX3rUkunl5Hoq8AgCW3kUtILkjyj0m+Y3p9Ismv3Mb8Y5N8ZGZ/3zS2Xnerqj1VdWlVffOhJlTVWdOcPfv379/AWwMAi1JV/1hVn5j5+YnZ/cOcNve+YqpNbwEAg9rITTy/uLu/bWb/JVV1+SbXM+uB3X1tVT04yduq6r3d/cHZCd19fpLzk2Tnzp09x1oAgE3S3fdawMcesa+YatNbAMCgNrIC48aq+pqDO1X1mCQ33sb8a5M8YGb/uGlsXbr72unnNUkuSfKIDdQKAAyqqu53W6/DnKavAIAlt5EVGN+b5LXTvTAqyXVZvVHW4exOckJVHZ/VBuOMJM9czwdV1dFJPtXdN1fV5yd5TJKf2kCtAMC4LkvSWe0n1uqsPlJ1LX0FACy5jTyF5PIkX1FV9572D3eN6sH5B6rq7CRvSbIjyQXdfWVVnZtkT3fvqqpHJvmdJEcn+aaqekl3f1mSL01y3nQTrs9J8rI1dxkHALao7j7+dpyjrwCAJXfEAKOqntXdv1ZVz18zniTp7p853LndfVGSi9aMvWhme3dWl4CuPe/Pk3z5kWoDALa2aXXECUnudnCsu//kUHP1FQCw3NazAuOe089F3HALANimquo/J/mBrIYOlyf56iR/keTxCywLABjUEQOM7j5v+vmS+ZcDACyRH0jyyCSXdvfXVdVJSX5ywTUBAINa91NIquqnqureVfW5VfXWqtpfVc+aZ3EAwLZ2U3fflCRVddfu/pskX7LgmgCAQW3kMapPnG7c+Y1JPpTkIUl+aB5FAQBLYV9V3TfJ7ya5uKrelOTvFloRADCsjTxG9eDcpyR5Y3ffcPBGngAAG9Xd3zJtrlTV25PcJ8kfLrAkAGBgG1mB8ftV9TdJvirJW6vqmCQ3zacsAGC7q6qvrqp7JUl3vyPJJUkesdCiAIBhrTvA6O5zkvyHJDu7+zNJ/inJ6fMqDADY9n4hySdn9j85jQEA/CtHvISkqh7f3W+rqm+dGZud8tvzKAwA2Paqu/vgTnffWlUbubwVAFgi62kSvjbJ25J80yGOdQQYAMDtc01VfX/+ZdXF9yW5ZoH1AAADO2KA0d0vnn4+e/7lAABL5HuS/GySF2b1S5G3JjlroRUBAMNa9z0wquonp0edHdw/uqp+Yi5VAQDbXnf/Q3ef0d1f0N3/pruf2d3/sOi6AIAxbeQpJE/u7o8f3Onu65N8w6ZXBAAshao6sareWlXvm/YfVlUvXHRdAMCYNhJg7Kiqux7cqaq7J7nrbcwHALgtv5TkBUk+kyTdfUWSMxZaEQAwrI3c6fvXk7y1qn5l2n92ktdufkkAwJK4R3e/e83TzQ4sqhgAYGzrDjC6++VV9VdJnjANvbS73zKfsgCAJfDRqvrirN7AM1X1tCR/v9iSAIBRbfRZ63+d5EB3/3FV3aOq7tXd/ziPwgCAbe+5Sc5PclJVXZvkb5N852JLAgBGtZGnkHx3kt9Mct40dGyS351DTQDAEujua7r7CUmOSXJSkq9N8jWLrQoAGNVGbuL53CSPSfKJJOnuDyT5gnkUBQBsX1V176p6QVX9XFWdmuRTSc5MsjfJdyy2OgBgVBu5hOTm7v70wRttVdVRma5ZBQDYgNcluT7JXyT57iQ/lqSSfEt3X77AugCAgW0kwHhHVf1okrtP35Z8X5Lfm09ZAMA29uDu/vIkqapfzuqNO7+ou29abFkAwMg2cgnJjyTZn+S9Sf5LkouSvHAeRQEA29pnDm509y1J9gkvAIAjWdcKjKrakeTK7j4pyS/NtyQAYJv7iqr6xLRdWV3d+Ylpu7v73osrDQAY1boCjO6+paqurqov6u4Pz7soAGD76u4di64BANh6NnIPjKOTXFlV707yTwcHu/upm14VAAAAwIyNBBg/PrcqAAAAAG7DEQOMqrpbku9J8pCs3sDzNd19YN6FAQAAABy0nqeQvDbJzqyGF09O8tNzrQgAAABgjfVcQvLQmWe1vybJu+dbEgAAAMBnW88KjNlntbt0BAAAALjTrWcFhme1AwAAAAt1xADDs9oBAACARVvPJSQAAAAACyXAAAAAAIYnwAAAAACGJ8BgYVZWVlJVm/ZaWVlZ9K8EAADAnKznKSQwFysrK0cMHU455ZQkySWXXDL3egAAABiXFRgAAAAMw0ptDscKDAAAAIZhpTaHYwUGAAAAMDwBBgAAADA8AQYAAAAwPAEGAAAAMDwBBgAAADA8AQYAAAAwvLkGGFV1WlVdXVV7q+qcQxx/XFX9ZVUdqKqnrTl2ZlV9YHqdOc86AYCtQW8BAMvrqHm9cVXtSPLqJKcm2Zdkd1Xt6u6rZqZ9OMl3JfnBNefeL8mLk+xM0kkum869fl71Atvbqy5+/6JLWGr7rr8xiX+HRXveqScuuoQ7RG8BAMttniswTk6yt7uv6e5PJ7kwyemzE7r7Q919RZJb15z7pCQXd/d1U2NxcZLT5lgrADA+vQUALLF5BhjHJvnIzP6+aWzTzq2qs6pqT1Xt2b9//+0uFADYEvQWALDEtvRNPLv7/O7e2d07jznmmEWXAwBscXoLABjXPAOMa5M8YGb/uGls3ucCANuT3gIAltg8A4zdSU6oquOr6i5Jzkiya53nviXJE6vq6Ko6OskTpzEAYHnpLQBgic0twOjuA0nOzmpz8NdJ3tDdV1bVuVX11CSpqkdW1b4k357kvKq6cjr3uiQvzWqjsjvJudMYALCk9BYAsNzm9hjVJOnui5JctGbsRTPbu7O6hPNQ516Q5IJ51gcAbC16CwBYXlv6Jp4AAADAchBgAAAAAMMTYAAAAADDE2AAAAAAwxNgAAAAAMMTYAAAAADDE2AAAAAAwxNgAAAAAMMTYAAAAADDE2AAAAAAwxNgAAAAAMMTYAAAAADDE2AAAAAAwxNgAAAAAMMTYAAAAADDE2AAAAAAwxNgAAAAAMMTYAAAAADDE2AAAAAAwxNgAAAAAMMTYAAAAADDE2AAAAAAwxNgAAAAAMMTYAAAAADDE2AAAAAAwxNgAAAAAMMTYAAAAADDE2AAAAAAwxNgAAAAAMMTYAAAAADDE2AAAAAAwxNgAAAAAMMTYAAAAADDE2AAAAAAwxNgAAAAAMMTYAAAAADDE2AAAAAAwxNgAAAAAMMTYAAAAADDE2AAAAAAwxNgAAAAAMMTYAAAAADDE2AAAAAAwxNgAAAAAMOba4BRVadV1dVVtbeqzjnE8btW1eun4++qqgdN4w+qqhur6vLp9YvzrBMA2Br0FgCwvI6a1xtX1Y4kr05yapJ9SXZX1a7uvmpm2nOSXN/dD6mqM5K8PMnTp2Mf7O6Hz6s+AGBr0VsAwHKb5wqMk5Ps7e5ruvvTSS5McvqaOacnee20/ZtJvr6qao41AQBbl94CAJbYPAOMY5N8ZGZ/3zR2yDndfSDJDUnuPx07vqreU1XvqKrHHuoDquqsqtpTVXv279+/udUDAKPRWwDAEhv1Jp5/n+SLuvsRSZ6f5P9W1b3XTuru87t7Z3fvPOaYY+70IgGALUNvAQBb3DwDjGuTPGBm/7hp7JBzquqoJPdJ8rHuvrm7P5Yk3X1Zkg8mOXGOtQIA49NbAMASm2eAsTvJCVV1fFXdJckZSXatmbMryZnT9tOSvK27u6qOmW7Ulap6cJITklwzx1oBgPHpLQBgic3tKSTdfaCqzk7yliQ7klzQ3VdW1blJ9nT3riSvSfK6qtqb5LqsNiJJ8rgk51bVZ5LcmuR7uvu6edUKAIxPbwEAy21uAUaSdPdFSS5aM/aime2bknz7Ic77rSS/Nc/aAICtR28BAMtr1Jt4AgAAAPwzAQYAAAAwPAEGAAAAMDwBBgAAADA8AQYAAAAwPAEGAAAAMLy5PkYVAABgO3rVxe9fdAlLbd/1Nybx77Bozzv1xDv186zAAABgW1hZWUlVbdprZWVl0b8SADOswAAAYFtYWVk5YuhwyimnJEkuueSSudcDwOayAgMAAAAYngADAAAAGJ4AAwAAABieAAMAAAAYngADAAAAGJ4AAwAAABiex6gewasufv+iS1hq+66/MYl/h0V73qknLroEAABgyVmBAQAAAAxPgAEAAAAMT4ABAAAADE+AAQAAAAxPgAEAAAAMT4ABAAAADE+AAQAAAAxPgAEAAAAMT4ABAAAADE+AAQAAAAxPgAEAAAAMT4ABAAAADE+AAQAAAAxPgAEAAAAMT4ABAAAADE+AAQAAAAxPgAEAAAAMT4ABAAAADE+AAQAAAAxPgAEAAAAMT4ABAAAADE+AAQAAAAzvqEUXAACwTF518fsXXcJS23f9jUn8Oyza8049cdElAFuQFRgAAADA8AQYAAAAwPAEGAAAAMDwBBgAAADA8AQYAAAAwPDmGmBU1WlVdXVV7a2qcw5x/K5V9frp+Luq6kEzx14wjV9dVU+aZ50AwNagtwCA5TW3AKOqdiR5dZInJ3lokmdU1UPXTHtOkuu7+yFJXpXk5dO5D01yRpIvS3Jakp+f3g8AWFJ6CwBYbvNcgXFykr3dfU13fzrJhUlOXzPn9CSvnbZ/M8nXV1VN4xd2983d/bdJ9k7vBwAsL70FACyxo+b43scm+cjM/r4kjzrcnO4+UFU3JLn/NH7pmnOPXfsBVXVWkrOm3U9W1dWbUzqD+fznP/FLPrroIpbZ8xddANuFv+UFm+Pf8gPn99afRW/BZvH/0YLpLdgk/pYX7M7uLeYZYMxdd5+f5PxF18F8VdWe7t656DqAO8bfMluB3mI5+P8Itgd/y8tnnpeQXJvkATP7x01jh5xTVUcluU+Sj63zXABguegtAGCJzTPA2J3khKo6vqruktUbZ+1aM2dXkjOn7acleVt39zR+xnQn8eOTnJDk3XOsFQAYn94CAJbY3C4hma47PTvJW5LsSHJBd19ZVecm2dPdu5K8Jsnrqmpvkuuy2ohkmveGJFclOZDkud19y7xqZXiW8sL24G+ZO0RvwSby/xFsD/6Wl0ytfikBAAAAMK55XkICAAAAsCkEGAAAAMDwBBgsVFV98hBjK1V1bVVdPr1eNo1fUlUfrqqamfu7h3oP4I6rqq6qX5vZP6qq9lfV79+O93pQVT1zZv+Uqrph+hv/66p68WbVDSw3vQWMS2/BHSXAYFSv6u6HT69zZsY/nuQxSVJV903y7xZQGyyLf0ry76vq7tP+qbn9j518UJJnrhl7Z3c/PMnOJM+qqq+8ne8NsB56C1g8vQV3iACDrebCTHeUT/KtSX57gbXAMrgoyVOm7Wck+Y2DB6rqftM3lVdU1aVV9bBp/GtnvuV8T1XdK8nLkjx2Gnve7Ad09z8luSzJQ6rq4dN7XVFVv1NVR0/veUlV/a/p/PdV1cl3wu8OLAe9Bdy59BbcbgIMRvW8mf+knjQz/tYkj6uqHVltNl6/mPJgaVyY5IyquluShyV518yxlyR5T3c/LMmPJvnVafwHs/qIyocneWySG5Ock+lbke5+1ewHVNX9k3x1kiun9/iR6T3fm2R2+ec9pvf8viQXbOYvCSwFvQWMQW/B7XbUoguAw3hVd7/yEOO3JPnTrDYYd+/uD81ctgpssu6+oqoelNVvSC5ac/hrknzbNO9tVXX/qrp3kj9L8jNV9etJfru79x3m7/SxVfWeJLdm9VuUfUnu293vmI6/NskbZ+b/xvRZf1JV966q+3b3xzfj9wSWgt4CBqC34I4QYLAVXZjkd5KsLLgOWBa7krwyySlJ7n+kyd39sqr6gyTfkOTP1nzTOeud3f2NB3eq6j5Heusj7APcXnoLuHPpLbhdXELCVvTOJP8jM9fLAXN1QZKXdPd714y/M8l3Jqt3/k7y0e7+RFV9cXe/t7tfnmR3kpOS/GOSe93Wh3T3DUmur6rHTkP/Mck7ZqY8ffqsr0lywzQfYDPoLeDOpbfgdrECg0W7R1Xtm9n/mSOd0N2d1cQWuBN0974kP3uIQytJLqiqK5J8KsmZ0/h/raqvy+ryzSuTvHnavqWq/irJ/0nynsN83JlJfrGq7pHkmiTPnjl207Qs9HOT/Kc78jsB25reAgant+D2qtX/rwFgXFV1SZIf7O49i64FANj69BZbk0tIAAAAgOFZgQEAAAAMzwoMAAAAYHgCDAAAAGB4AgwAAABgeAIMAAAAYHgCDAAAAGB4/x8tAnvmokGu6AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### EXERCISE CELL ###\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for m_id, metric in enumerate(metrics.keys()):\n",
    "    \n",
    "    # Create the subplot for the current metric\n",
    "    plt.subplot(1, 2, m_id + 1)\n",
    "\n",
    "    # Compute means, standard deviations, and labels for each model\n",
    "    means, yerrs, labels = [], [], []\n",
    "    for model_label, model_scores in metrics[metric].items():\n",
    "        means.append(np.mean(model_scores))\n",
    "        yerrs.append(np.std(model_scores))\n",
    "        labels.append(model_label)\n",
    "    \n",
    "    # Plot values\n",
    "    x_pos = np.arange(len(labels))\n",
    "    plt.bar(x_pos, means, yerr=yerrs, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "    \n",
    "    # Make decorations\n",
    "    plt.xticks(x_pos, labels)\n",
    "    plt.ylabel(metric)\n",
    "    plt.ylim(0, .3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What can we conclude from the above plots?\n",
    "- How can we find tune the latent factor model, to get better performance?\n",
    "\n",
    "**Hint**. Currently, the latent factor model is optimized for rating prediction, not for providing good rankings (recommended lists to users), which is the main scope of metrics like precision and recall. Therefore, often, the training set used to optimized a latent factor model is often enrighed with \"negative examples\", i.e., unseen interactions between users and items where the rating is set to 0 (remember that this is just an assumption, given that those interactions are unobserved). You can try to extend the training set with this type of interactions (usually the ratio between observed and unobserved interactions in the training set is around 1:10) and see how the performance in terms of precision and recall changes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise #6\n",
    "\n",
    "- Create and provide an example usage of a function that, given a user id, prints the top k items (title included) recommended to that user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXERCISE CELL ###\n",
    "def show_top_k(model, pred_func, train_ratings, test_ratings, no_users, no_items, items, k=10, user_id=0):\n",
    "    pid_array = np.arange(no_items, dtype=np.int32)\n",
    "    \n",
    "    user_test_rating = test_ratings[test_ratings['user_id'] == user_id]\n",
    "    \n",
    "    train_pids = train_ratings[train_ratings['user_id'] == user_id]['item_id'].values\n",
    "    test_pids = set(user_test_rating['item_id'].values)\n",
    "    \n",
    "    predictions = pred_func(model, user_id, pid_array, train_ratings)\n",
    "    predictions[train_pids] = - math.inf\n",
    "    top_k = set(np.argsort(-predictions)[:k])\n",
    "    \n",
    "    for rank, item_id in enumerate(top_k):\n",
    "        orig_item = ratings[ratings['item_id'] == item_id]['original_item_id'].values[0]\n",
    "        item_title = items[items['item_id'] == orig_item]['title'].values[0]\n",
    "        print('#', rank+1, item_id, item_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 646 Pather Panchali (1955)\n",
      "# 2 647 Aparajito (1956)\n",
      "# 3 3080 Circus, The (1928)\n",
      "# 4 3111 For All Mankind (1989)\n",
      "# 5 2698 Sanjuro (1962)\n",
      "# 6 588 Great Day in Harlem, A (1994)\n",
      "# 7 2158 Nights of Cabiria (Le Notti di Cabiria) (1957)\n",
      "# 8 208 Before the Rain (Pred dozhdot) (1994)\n",
      "# 9 628 Cold Fever (Á köldum klaka) (1994)\n",
      "# 10 2876 Chushingura (1962)\n"
     ]
    }
   ],
   "source": [
    "show_top_k(model, predict_from_latent, train_ratings, test_ratings, no_users, no_items, items, k=10, user_id=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further steps\n",
    "---\n",
    "\n",
    "- Repeat the analysis on another dataset. \n",
    "- Repeat on another evaluation methods (e.g., cross validation) and splitting strategies (e.g., fixed time stamp for all). \n",
    "- Repeat on another latent factor models, more advanced in terms of architecture. \n",
    "- Compare your model with traditional models manipulated by Surprise and seen in the previous lecture.\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "---\n",
    "\n",
    "In this tutorial, we introduced latent factor models, from their definition to their evaluation. Furthermore, we presented several evaluation methods and performance metrics, that are important for assessing the impact of the solution on the real world."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lesson_04_01_Recommender_Systems_Case_Study",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
